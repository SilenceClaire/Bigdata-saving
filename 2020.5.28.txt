陈思日记
今天完成了作业的编写的文档，因为已经做完了作业。觉得在修改代码的时候主要是靠读懂原有代码，但是还是有一些原理不太懂比如scala中的RDD，collect的原理，在wordcount中每一步的作用。经过查资料，找到了一些对于理解课上scala和spark代码的基础知识：
1. collect是spark中的行动算子，是真正触发计算的。将数据收集到Driver端显示
2. map, group等操作是转化算子，只是改变的数据的结构。
3. sr是驱动器。
4. 在分析代码的过程中抓住代码执行过程中数据结构的转换。
5. 代码中的local模式是运行在本地计算机上的模式，local[*]这种模式让电脑按照CPU最多cores设置线程数。
6. textFile("Input"):读取本都文件input文件夹数据
7. flatMap(_.split(""))压平操作，按照空格跟戈夫将遗憾给数据映射成一个单词。
